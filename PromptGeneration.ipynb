{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000c383-b872-4e6a-a5b4-609753af05ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc2eb81-8f68-4c97-98e0-e2c1767304c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/video-generation-Deforum/.myenv/miniconda/envs/deforum/lib/python3.9/site-packages/transformers/modeling_utils.py:402: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n",
      "/home/ec2-user/SageMaker/video-generation-Deforum/.myenv/miniconda/envs/deforum/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/ec2-user/SageMaker/video-generation-Deforum/.myenv/miniconda/envs/deforum/lib/python3.9/site-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n",
      "/home/ec2-user/SageMaker/video-generation-Deforum/.myenv/miniconda/envs/deforum/lib/python3.9/site-packages/safetensors/torch.py:99: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"FredZhang7/distilgpt2-stable-diffusion-v2\")#\"Gustavosta/MagicPrompt-Stable-Diffusion\") # \"FredZhang7/distilgpt2-stable-diffusion-v2\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Gustavosta/MagicPrompt-Stable-Diffusion\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Gustavosta/MagicPrompt-Stable-Diffusion\")\n",
    "\n",
    "def clean_prompts(input_prompts):\n",
    "    prompts=[]\n",
    "    tokenizer_ner = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "    model_ner = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "    nlp = pipeline(\"ner\", model=model_ner, tokenizer=tokenizer_ner)\n",
    "    \n",
    "    for text in input_prompts:\n",
    "        ner_results = nlp(text)\n",
    "        names=[]\n",
    "        for result in ner_results:\n",
    "            names.append(result['word'])\n",
    "        output_text=\"\"\n",
    "        elements = text.split(',')\n",
    "        # print(elements)\n",
    "        for element in elements:\n",
    "            if (element.find('by') == -1) and (element.find('style of') == -1):# and not any(e in element for e in names):\n",
    "                output_text += f\",{element}\"\n",
    "        prompts.append(output_text[1:])\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5f6d018-8764-4f2c-b6d7-fd6a3d29057e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['woman dancing alone in a room, with the music blasting from a speaker-sustacean spaceship, masterpiece, award-winning, sharp focus, intricate concept art, ambient lighting, 8k, octane render, cgsociety, trending on artstation, artstationhd, artstationhq, unreal engine, 4k',\n",
       " 'woman dancing alone in a room, with the music blasting from a speaker in the back, wearing a long coat, very beautiful, intricate, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, 8 k, unreal engine 5, global illumination, radiant light, detailed and intricate',\n",
       " 'woman dancing alone in a room, with the music blasting from a speaker, with a red dress, wlop, ilya kuvshinov, artgerm, krenz cushart, greg rutkowski, hiroaki samura, range murata, james jean, katsuhiro otomo, erik jones, serov, surikov,',\n",
       " 'woman dancing alone in a room, with the music blasting from a speaker music video, canon 5d 50 mm lens, artstation, deviantart, artstation hq, film still, detailed face, symmetrical face, masterpiece, volumetric lighting, dark red moon light, cgsociety, octane render, 4k, cinematic, hyperrealism',\n",
       " 'woman dancing alone in a room, with the music blasting from a speaker, behance contest winner, fantasy art, concept art, matte painting, official art, matte drawing, matte drawing, artstation hq, matte drawing, matte drawing, photoillustration, official art, matte painting, cinematic painting, hd, hdr, photorealistic, 8 k, intricate, award winning,']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=\"woman dancing alone in a room, with the music blasting from a speaker\"\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "if input_ids.shape[1] == 0:\n",
    "    input_ids = torch.asarray(\n",
    "        [[current.tokenizer.bos_token_id]], dtype=torch.long)\n",
    "temperature = 1\n",
    "top_k = 12\n",
    "min_length = 40\n",
    "max_length = 90\n",
    "repetition_penalty=1\n",
    "num_return_sequences=5\n",
    "output = model.generate(input_ids,\n",
    "                do_sample=True,\n",
    "                temperature=max(float(temperature), 1e-6),\n",
    "                top_k=round(top_k),\n",
    "                max_length=max_length,\n",
    "                num_return_sequences=num_return_sequences,\n",
    "                repetition_penalty=float(repetition_penalty),\n",
    "                pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id\n",
    "                       )\n",
    "texts = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "clean_prompts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bed5e9-091e-4181-9f28-8c94c8e62201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_deforum",
   "language": "python",
   "name": "conda_deforum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
